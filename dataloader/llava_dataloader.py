from torch.utils.data import Dataset, DataLoader
from PIL import Image
from transformers import AutoTokenizer
from tqdm import tqdm

import json
import torch
import os


class BlipLaionCC558KDataset(Dataset):
    def __init__(self, json_path, img_root, tokenizer, vis_processor, max_length=128):
        with open(json_path, "r") as f:
            self.data = json.load(f)
        self.img_root = img_root
        self.tokenizer = tokenizer
        self.vis_processor = vis_processor  # ViTìš© ì „ì²˜ë¦¬ (Resize, Normalize ë“±)
        self.max_length = max_length

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        item = self.data[idx]

        # 2. ì´ë¯¸ì§€ ë¡œë“œ
        img_path = os.path.join(self.img_root, item["image"])

        try:
            image = Image.open(img_path).convert("RGB")
            image_tensor = self.vis_processor(image)  # [3, 224, 224]
        except Exception as e:
            return self.__getitem__((idx + 1) % len(self.data))

        # 3. ëŒ€í™” ë°ì´í„°ì—ì„œ ìº¡ì…˜(GPT ë‹µë³€) ì¶”ì¶œ
        # conversations[0]: Human ì§ˆë¬¸, conversations[1]: GPT ë‹µë³€
        convs = item["conversations"]
        caption = convs[1]["value"]

        # 4. í† í°í™” (í”„ë¡¬í”„íŠ¸ êµ¬ì„±)
        full_text = f"Describe this image: {caption}{self.tokenizer.eos_token}"

        tokenized = self.tokenizer(
            full_text,
            return_tensors="pt",
            padding="max_length",
            truncation=True,
            max_length=self.max_length,
            add_special_tokens=True,
        )

        input_ids = tokenized.input_ids.squeeze()

        # 5. Labels ìƒì„± (íŒ¨ë”© í† í° Loss ì œì™¸ ì²˜ë¦¬)
        labels = input_ids.clone()
        if self.tokenizer.pad_token_id is not None:
            labels[labels == self.tokenizer.pad_token_id] = -100
        else:
            # Solar/Llama ê³„ì—´ì—ì„œ pad_tokenì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ì„ ê²½ìš° eos_token ì‚¬ìš© ê°€ëŠ¥ì„± ëŒ€ë¹„
            labels[labels == self.tokenizer.eos_token_id] = -100

        return {"image": image_tensor, "input_ids": input_ids, "labels": labels}


def get_blip_laion_cc_558k_dataloader(
    model_name: str,
    vis_processor,
    json_path: str,
    img_root: str,
):
    # 1. í† í¬ë‚˜ì´ì € ì¤€ë¹„ (Llama-3 ê¸°ì¤€)
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token

    # 2. ë°ì´í„°ì…‹ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    # img_rootëŠ” ì´ë¯¸ì§€ë“¤ì´ ë“¤ì–´ìˆëŠ” ìµœìƒìœ„ í´ë” ê²½ë¡œì…ë‹ˆë‹¤.
    dataset = BlipLaionCC558KDataset(
        json_path=json_path,
        img_root=img_root,
        tokenizer=tokenizer,
        vis_processor=vis_processor,  # ì´ì „ì— ì‚¬ìš©í•œ ViT ì „ì²˜ë¦¬ í•¨ìˆ˜
    )

    # 3. ë¡œë” ìƒì„±
    train_loader = DataLoader(
        dataset,
        batch_size=8,  # 8-bit ì–‘ìí™” ì‚¬ìš© ì‹œ ë” í‚¤ìš¸ ìˆ˜ ìˆìŒ
        shuffle=True,
        num_workers=8,  # A6000 ì„œë²„ë¼ë©´ CPU ì½”ì–´ì— ë§ì¶° 8~16 ê¶Œì¥
        pin_memory=True,
    )

    return train_loader


class LlavaStage3Dataset(Dataset):
    def __init__(self, json_path, img_root, tokenizer, vis_processor, max_length=1024):
        with open(json_path, "r") as f:
            self.data = json.load(f)

        self.tokenizer = tokenizer
        self.vis_processor = vis_processor
        self.max_length = max_length

        # í•˜ìœ„ í´ë” ì´ë¯¸ì§€ ê²½ë¡œ ë¯¸ë¦¬ ë§µí•‘ (í•™ìŠµ ì‹œ ì†ë„ ì €í•˜ ë°©ì§€)
        print("ì´ë¯¸ì§€ ê²½ë¡œ ì¸ë±ì‹± ì¤‘...")
        self.image_map = {}
        for root, _, files in os.walk(img_root):
            for file in files:
                self.image_map[file] = os.path.join(root, file)
        print(f"ì¸ë±ì‹± ì™„ë£Œ: {len(self.image_map)}ê°œì˜ ì´ë¯¸ì§€ íƒì§€")

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        item = self.data[idx]

        # 1. ì´ë¯¸ì§€ ì²˜ë¦¬
        image_tensor = None
        if "image" in item:
            file_name = os.path.basename(item["image"])
            actual_path = self.image_map.get(file_name)
            if actual_path:
                image = Image.open(actual_path).convert("RGB")
                image_tensor = self.vis_processor(image)

        # ì´ë¯¸ì§€ê°€ ì—†ëŠ” ë°ì´í„°(í…ìŠ¤íŠ¸ ì „ìš©)ì¸ ê²½ìš° ì²˜ë¦¬
        if image_tensor is None:
            image_tensor = torch.zeros(3, 224, 224)

        # 2. Solar ëŒ€í™” í¬ë§· êµ¬ì„±
        # í¬ë§·: ### User: <image>\nì§ˆë¬¸\n\n### Assistant: ë‹µë³€</s>
        convs = item["conversations"]
        full_text = ""
        for i, conv in enumerate(convs):
            role = "### User" if conv["from"] == "human" else "### Assistant"
            value = conv["value"]

            if i == 0 and "<image>" in value:  # ì´ë¯¸ì§€ í† í° ì²˜ë¦¬
                value = value.replace("<image>", "").strip()
                full_text += f"{role}: <image>\n{value}\n\n"
            else:
                full_text += f"{role}: {value}\n\n"

        full_text = full_text.strip() + self.tokenizer.eos_token

        # 3. í† í°í™” ë° ë ˆì´ë¸” ìƒì„±
        encodings = self.tokenizer(
            full_text,
            return_tensors="pt",
            padding="max_length",
            truncation=True,
            max_length=self.max_length,
        )

        input_ids = encodings.input_ids.squeeze()
        labels = input_ids.clone()

        return {"image": image_tensor, "input_ids": input_ids, "labels": labels}


def verify_and_clean_dataset_recursive(json_path, img_root, output_json_path):
    # 1. JSON ë¡œë“œ
    with open(json_path, "r") as f:
        data = json.load(f)

    print(f"ì´ ë°ì´í„° ê°œìˆ˜: {len(data)}")

    # 2. ëª¨ë“  í•˜ìœ„ íŒŒì¼ ê²½ë¡œ ë¯¸ë¦¬ ë§µí•‘ (ì†ë„ í–¥ìƒì„ ìœ„í•´)
    # íŒŒì¼ëª… -> ì‹¤ì œ ì „ì²´ ê²½ë¡œ ë¡œ ë”•ì…”ë„ˆë¦¬ë¥¼ ë§Œë“­ë‹ˆë‹¤.
    print("ë””ë ‰í† ë¦¬ êµ¬ì¡° ìŠ¤ìº” ì¤‘... (ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    image_map = {}
    for root, dirs, files in os.walk(img_root):
        for file in files:
            # íŒŒì¼ëª…ì„ í‚¤ë¡œ, ì „ì²´ ê²½ë¡œë¥¼ ê°’ìœ¼ë¡œ ì €ì¥
            image_map[file] = os.path.join(root, file)

    print(f"ìŠ¤ìº” ì™„ë£Œ! ë°œê²¬ëœ ì´ ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜: {len(image_map)}")

    clean_data = []
    missing_count = 0

    # 3. ë°ì´í„° ê²€ì¦
    print("ë°ì´í„°ì…‹ í•„í„°ë§ ì¤‘...")
    for item in tqdm(data):
        if "image" not in item:
            clean_data.append(item)
            continue

        file_name = os.path.basename(item["image"])

        # ë¯¸ë¦¬ ë§Œë“¤ì–´ë‘” ë§µì—ì„œ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
        if file_name in image_map:
            # ë‚˜ì¤‘ì— í•™ìŠµí•  ë•Œ í¸í•˜ë„ë¡ ì‹¤ì œ ê²½ë¡œë¡œ ì—…ë°ì´íŠ¸í•´ì£¼ë©´ ë” ì¢‹ìŠµë‹ˆë‹¤.
            # item['image'] = image_map[file_name]
            clean_data.append(item)
        else:
            missing_count += 1

    # 4. ê²°ê³¼ ë³´ê³ 
    print("\n" + "=" * 30)
    print(f"âœ… ìµœì¢… ì‚¬ìš© ê°€ëŠ¥ ë°ì´í„°: {len(clean_data)}")
    print(f"âŒ ì‹¤ì œë¡œ ëˆ„ë½ëœ ë°ì´í„°: {missing_count}")
    print("=" * 30)

    # 5. ì €ì¥
    with open(output_json_path, "w") as f:
        json.dump(clean_data, f, indent=4)
    print(f"ğŸ’¾ í•„í„°ë§ëœ JSON ì €ì¥ ì™„ë£Œ: {output_json_path}")
