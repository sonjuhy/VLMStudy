from torch.amp import autocast, GradScaler
from dataloader.imagenet_1k_dataloader import (
    get_imagenet_loaders,
    get_imagenet_loaders_fsdp,
)
from vision.vit_model import ViTEncoder
from tqdm import tqdm

from torch.distributed.fsdp import (
    FullyShardedDataParallel as FSDP,
    FullStateDictConfig,
    StateDictType,
)

import os
import torch
import torch.distributed as dist
import torch.optim as optim
import torch.nn as nn
import pandas as pd
import glob


def save_checkpoint(epoch, model, optimizer, scaler, loss, path="checkpoints"):
    if not os.path.exists(path):
        os.makedirs(path)

    checkpoint_path = os.path.join(
        path, f"vit_imagenet_1k_checkpoint_epoch_{epoch}.pth"
    )

    torch.save(
        {
            "epoch": epoch,
            "model_state_dict": model.state_dict(),
            "optimizer_state_dict": optimizer.state_dict(),
            "scaler_state_dict": scaler.state_dict(),
            "loss": loss,
        },
        checkpoint_path,
    )
    print(f"--- Checkpoint saved at: {checkpoint_path} ---")


def load_checkpoint(path, model, optimizer, scaler):
    if os.path.isfile(path):
        print(f"--- Loading checkpoint: {path} ---")
        checkpoint = torch.load(path)
        model.load_state_dict(checkpoint["model_state_dict"])
        optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
        scaler.load_state_dict(checkpoint["scaler_state_dict"])
        start_epoch = checkpoint["epoch"]
        print(f"--- Resuming from epoch {start_epoch} ---")
        return start_epoch
    else:
        print("--- No checkpoint found, starting from scratch ---")
        return 0


def train(
    epochs: int,
    device: torch.device = torch.device("cpu"),
    model: nn.Module = None,
    train_loader: torch.utils.data.DataLoader = None,
    optimizer: optim.Optimizer = None,
    criterion: nn.Module = None,
    scaler: GradScaler = None,
    scheduler: optim.lr_scheduler = None,
):
    for epoch in range(epochs):
        model.train()

        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}")
        for inputs, targets in pbar:
            # for batch_idx, (inputs, targets) in enumerate(train_loader):
            inputs, targets = inputs.to(device), targets.to(device)

            optimizer.zero_grad()

            # --- í˜¼í•© ì •ë°€ë„ í•µì‹¬ êµ¬ê°„ ---
            # 3. autocastë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆœì „íŒŒ(Forward) ì—°ì‚° ìˆ˜í–‰
            with autocast(device_type=device.type):
                outputs = model(inputs)
                loss = criterion(outputs, targets)

            # 4. ìŠ¤ì¼€ì¼ë§ëœ Lossë¡œ ì—­ì „íŒŒ(Backward)
            scaler.scale(loss).backward()

            # 5. ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ (ë‚´ë¶€ì ìœ¼ë¡œ ìŠ¤ì¼€ì¼ ì¡°ì • ë° Gradient Clipping ê°€ëŠ¥)
            scaler.step(optimizer)
            scaler.update()
            # scheduler.step()

            pbar.set_postfix(loss=f"{loss.item():.4f}")

        scheduler.step()
        # if (epoch + 1) % 10 == 0:
        save_checkpoint(epoch + 1, model, optimizer, scaler, loss.item())


def evaluate_all_checkpoints(
    checkpoint_dir,
    device=torch.device("cuda"),
    save_name="evaluation_results.csv",
):
    _, val_loader = get_imagenet_loaders(batch_size=256)

    img_size = 224  # ImageNet í‘œì¤€ í•´ìƒë„
    patch_size = 16  # 224/16 = 14x14 ì´ 196ê°œì˜ íŒ¨ì¹˜ ìƒì„±
    embedding_size = 768  # ViT-Base í‘œì¤€ ì„ë² ë”© ì°¨ì› (ë°˜ë“œì‹œ num_headsì˜ ë°°ìˆ˜ì—¬ì•¼ í•¨)
    num_class = 1000  # ImageNet-1Kì˜ í´ë˜ìŠ¤ ê°œìˆ˜
    num_heads = 12  # 768 / 12 = headë‹¹ 64ì°¨ì› (í‘œì¤€ ì„¤ì •)

    model = ViTEncoder(
        img_size=img_size,
        patch_size=patch_size,
        embedding_size=embedding_size,
        num_class=num_class,
        num_heads=num_heads,
        in_channels=3,
    ).to(device)
    model.eval()

    # 1. pth íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ë° ì •ë ¬ (ì—í¬í¬ ìˆœì„œëŒ€ë¡œ)
    checkpoint_files = glob.glob(os.path.join(checkpoint_dir, "*.pth"))
    # íŒŒì¼ëª…ì—ì„œ ìˆ«ìë¥¼ ì¶”ì¶œí•˜ì—¬ ì •ë ¬ (ì˜ˆ: epoch_10.pth -> 10)
    checkpoint_files.sort(
        key=lambda x: int("".join(filter(str.isdigit, os.path.basename(x))))
    )

    results = []

    print(f"Found {len(checkpoint_files)} checkpoints. Starting evaluation...")

    for cp_path in checkpoint_files:
        epoch_num = "".join(filter(str.isdigit, os.path.basename(cp_path)))
        print(f"\n[Epoch {epoch_num}] Loading {os.path.basename(cp_path)}...")

        # ëª¨ë¸ ë¡œë“œ
        checkpoint = torch.load(cp_path, map_location=device)
        # ë§Œì•½ ì²´í¬í¬ì¸íŠ¸ê°€ dict í˜•íƒœ(model_state_dict ë“±)ë¼ë©´ ì•„ë˜ì™€ ê°™ì´ ìˆ˜ì • í•„ìš”
        if isinstance(checkpoint, dict) and "model_state_dict" in checkpoint:
            model.load_state_dict(checkpoint["model_state_dict"])
        else:
            model.load_state_dict(checkpoint)

        top1_correct = 0
        top5_correct = 0
        total = 0

        with torch.no_grad():
            for inputs, targets in tqdm(
                val_loader, desc=f"Evaluating Epoch {epoch_num}", leave=False
            ):
                inputs, targets = inputs.to(device), targets.to(device)
                outputs = model(inputs)

                # Top-1 ë° Top-5 ì •í™•ë„ ê³„ì‚°
                _, pred = outputs.topk(5, 1, True, True)
                pred = pred.t()
                correct = pred.eq(targets.view(1, -1).expand_as(pred))

                top1_correct += (
                    correct[:1].reshape(-1).float().sum(0, keepdim=True).item()
                )
                top5_correct += (
                    correct[:5].reshape(-1).float().sum(0, keepdim=True).item()
                )
                total += targets.size(0)

        top1_acc = 100.0 * top1_correct / total
        top5_acc = 100.0 * top5_correct / total

        print(f"Done. Top-1: {top1_acc:.2f}%, Top-5: {top5_acc:.2f}%")

        results.append(
            {
                "epoch": int(epoch_num),
                "top1_acc": top1_acc,
                "top5_acc": top5_acc,
                "path": cp_path,
            }
        )

        # ì¤‘ê°„ ì €ì¥ (í˜¹ì‹œ ëª¨ë¥¼ ì¤‘ë‹¨ ëŒ€ë¹„)
        df = pd.DataFrame(results)
        df.to_csv(save_name, index=False)

    print(f"\nâœ¨ All evaluations finished! Results saved to {save_name}")

    # ìµœì ì˜ ëª¨ë¸ ì°¾ê¸°
    best_row = df.loc[df["top1_acc"].idxmax()]
    print(
        f"ğŸ† Best Model: Epoch {best_row['epoch']} with {best_row['top1_acc']:.2f}% Top-1 Acc"
    )
    return df


def imagenet_1k_end_to_end_test():
    # 1. ëª¨ë¸, ë°ì´í„°ë¡œë”, ì˜µí‹°ë§ˆì´ì € ì„¤ì •
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    img_size = 224  # ImageNet í‘œì¤€ í•´ìƒë„
    patch_size = 16  # 224/16 = 14x14 ì´ 196ê°œì˜ íŒ¨ì¹˜ ìƒì„±
    embedding_size = 768  # ViT-Base í‘œì¤€ ì„ë² ë”© ì°¨ì› (ë°˜ë“œì‹œ num_headsì˜ ë°°ìˆ˜ì—¬ì•¼ í•¨)
    num_class = 1000  # ImageNet-1Kì˜ í´ë˜ìŠ¤ ê°œìˆ˜
    num_heads = 12  # 768 / 12 = headë‹¹ 64ì°¨ì› (í‘œì¤€ ì„¤ì •)

    model = ViTEncoder(
        img_size=img_size,
        patch_size=patch_size,
        embedding_size=embedding_size,
        num_class=num_class,
        num_heads=num_heads,
        in_channels=3,
    ).to(device)
    train_loader, _ = get_imagenet_loaders(batch_size=256)

    # 2. í˜¼í•© ì •ë°€ë„ë¥¼ ìœ„í•œ GradScaler ì´ˆê¸°í™”
    epochs = 100
    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.05)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=epochs, eta_min=1e-6
    )
    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

    scaler = GradScaler()
    train(
        epochs=epochs,
        device=device,
        model=model,
        train_loader=train_loader,
        optimizer=optimizer,
        criterion=criterion,
        scaler=scaler,
        scheduler=scheduler,
    )


def save_fsdp_model(
    model: nn.Module,
    optimizer: torch.optim.Adam,
    epoch: int,
    path: str,
):
    # 1. ëª¨ë“  í”„ë¡œì„¸ìŠ¤ê°€ ê°€ì¤‘ì¹˜ë¥¼ ëª¨ìœ¼ë„ë¡ ì„¤ì •
    save_policy = FullStateDictConfig(offload_to_cpu=True, rank0_only=True)
    with FSDP.state_dict_type(model, StateDictType.FULL_STATE_DICT, save_policy):
        cpu_state = model.state_dict()

    # 2. Rank 0(ë§ˆìŠ¤í„° GPU)ì—ì„œë§Œ íŒŒì¼ë¡œ ê¸°ë¡
    if dist.get_rank() == 0:
        print(f"--> Saving checkpoint to {path}...")
        checkpoint = {
            "model_state": cpu_state,
            "optimizer_state": optimizer.state_dict(),  # ì˜µí‹°ë§ˆì´ì €ëŠ” ì¶”ê°€ ì²˜ë¦¬ê°€ ë³µì¡í•  ìˆ˜ ìˆìŒ
            "epoch": epoch,
        }
        torch.save(checkpoint, path)
        print("--> Checkpoint saved.")


def imagenet_1k_multi_gpu_train_test():
    if not torch.cuda.is_available():
        print("Must CUDA Avalialbe")
        return

    dist.init_process_group(backend="nccl")
    local_rank = int(os.environ["LOCAL_RANK"])
    torch.cuda.set_device(local_rank)
    rank = dist.get_rank()

    img_size = 224  # ImageNet í‘œì¤€ í•´ìƒë„
    patch_size = 16  # 224/16 = 14x14 ì´ 196ê°œì˜ íŒ¨ì¹˜ ìƒì„±
    embedding_size = 768  # ViT-Base í‘œì¤€ ì„ë² ë”© ì°¨ì› (ë°˜ë“œì‹œ num_headsì˜ ë°°ìˆ˜ì—¬ì•¼ í•¨)
    num_class = 1000  # ImageNet-1Kì˜ í´ë˜ìŠ¤ ê°œìˆ˜
    num_heads = 12  # 768 / 12 = headë‹¹ 64ì°¨ì› (í‘œì¤€ ì„¤ì •)
    epochs = 100

    model = ViTEncoder(
        img_size=img_size,
        patch_size=patch_size,
        embedding_size=embedding_size,
        num_class=num_class,
        num_heads=num_heads,
        in_channels=3,
    ).cuda()
    fsdp_model = FSDP(model)

    # DataSet
    train_loader, _, train_sampler = get_imagenet_loaders_fsdp(batch_size=256)
    optimizer = torch.optim.Adam(fsdp_model.parameters(), lr=1e-4)

    scheduler = optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=epochs, eta_min=1e-6
    )
    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

    scaler = GradScaler()
    for epoch in range(epochs):
        train_sampler.set_epoch(epoch=epoch)
        fsdp_model.train()

        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}")
        for inputs, targets in pbar:
            inputs, targets = inputs.cuda(), targets.cuda()
            outputs = fsdp_model(inputs)

            optimizer.zero_grad()
            with torch.autocast():
                loss = criterion(outputs, targets)
                # 4. ìŠ¤ì¼€ì¼ë§ëœ Lossë¡œ ì—­ì „íŒŒ(Backward)
                scaler.scale(loss).backward()

            # 5. ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ (ë‚´ë¶€ì ìœ¼ë¡œ ìŠ¤ì¼€ì¼ ì¡°ì • ë° Gradient Clipping ê°€ëŠ¥)
            scaler.step(optimizer)
            scaler.update()

            if rank == 0:
                pbar.set_postfix(loss=f"{loss.item():.4f}")
        scheduler.step()
        # [ì¶”ê°€] ë§¤ ì—í­ í˜¹ì€ íŠ¹ì • ì£¼ê¸°ì— ì €ì¥
        if (epoch + 1) % 10 == 0:
            save_fsdp_model(
                fsdp_model, optimizer, epoch, f"vit_fsdp_epoch_{epoch+1}.pth"
            )
    dist.destroy_process_group()

    # # GPU 2ê°œë¥¼ ëª¨ë‘ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •
    # torchrun --nproc_per_node=2 test.py
